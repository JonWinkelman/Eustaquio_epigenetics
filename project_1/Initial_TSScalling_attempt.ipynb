{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotly import offline as pyo\n",
    "from plotly import graph_objects as go\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndimage as ndi\n",
    "from jw_utils import parse_gff as pgf\n",
    "from jw_utils import parse_fasta as pf\n",
    "from jw_utils import parse_gbk as pgb\n",
    "from jw_utils import file_utils as fu\n",
    "from Bio import SeqIO\n",
    "import bisect\n",
    "import pysam\n",
    "from transcript_calling import tc_functions as tf\n",
    "from jw_utils import genome_utils as gu\n",
    "path_to_gff = '../references/FERM_BP3421.gff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gff = '../references/FERM_BP3421.gff'\n",
    "path_to_strGTF_neg = './merge_all_negStrand.gtf'\n",
    "path_to_valcount_dir = '../results/analysis/value_counts'\n",
    "path_to_annot_file = '../data/references/Reference_FERM_BP3421.gbk'\n",
    "path_to_fa_genomes = '../data/references/concat_references.fa'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f5dfd",
   "metadata": {},
   "source": [
    "## Code below from first attempt to find Eustaquio TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6bbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_align_obj = pysam.AlignmentFile(path_to_bam_mergedAlignments_neg, 'rb')\n",
    "bf1_pilup = sam_align_obj.pileup(contig='BF000000.1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5ddb39",
   "metadata": {},
   "source": [
    "## Description of initial steps\n",
    "#### raw data description './data/...'\n",
    "working directory: ('~/Dropbox/Trestle_projects/Eustaquio_lab/RNAseq_dash_app')\n",
    "1) 5 chromosomes/plasmids: ('BF000000.1', 'BF000000.2', 'BF000000.3', 'BF000000.4', 'BF000000.5') './data/references' \n",
    "    - combined these files into one fasta ( './data/references/concat_references.fa' )\n",
    "2) 12 paired end fastq files (6 R1 +  6 R2) ('../Illumina_RNA_Reads/fastq_files')\n",
    "    - aligned with bowtie2 with our nextflow pipeline (see the multiqc report) using standard settings (../new_alignments/Bowtie_aligned')\n",
    "    - extracted just 5' (rna) end of the paired end segment\n",
    "        -5â€™ end of reads with flags 147 or 163 faced same direction as predicted RNAs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All paths to data\n",
    "\n",
    "### Make a example of clean data and difference kernal and plot it\n",
    "\n",
    "y0 = np.full(50, 0)\n",
    "y1 = np.full(50, 1)\n",
    "y = np.concatenate([y0,y1])\n",
    "x = np.array(range(len(y)))\n",
    "t = ndi.convolve(y, [1,0,-1], mode='reflect')\n",
    "fig = pu.quick_line(x =x, y = t, name='convolved w diff kernal' )\n",
    "data = pu.quick_line(x =x, y = y, name='clean data'  )['data'][0]\n",
    "fig = fig.add_trace(data)\n",
    "pyo.plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3c3e4",
   "metadata": {},
   "source": [
    "### First processing steps\n",
    "1) Make dataframe of summed reads at each genomic position from all experiments\n",
    "2) Make transcription start site TssFinder object\n",
    "3) Find all tss windows and return df dictionary with reads for each gene. 100 nt before start codon up to start codon\n",
    "4) Make figure dictionary containing plotly figs for reads in the tss window and for the diff kernal-convolved reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import processing as pr\n",
    "df = pr.get_read_sums(path_to_valcount_dir,'BF000000.1')\n",
    "tf_sums = gp.TssFinder(path_to_annot_file, val_counts_df=df, contig_name='BF000000.1')\n",
    "tss_windows = tf_sums.get_region_hits(read_density_cut=0.2)\n",
    "fig_dict= pr.make_fig_dict(path_to_annot_file,contig_name='BF000000.1', kernal_type='diff',plot_kernal=False, read_density_cut=0.2)\n",
    "\n",
    "print(gb_dict['BF000000.1']['tmp_003403'].qualifiers['product'])\n",
    "f = fig_dict['tmp_003403']\n",
    "\n",
    "\n",
    "\n",
    "fig_dict= pr.make_fig_dict(path_to_annot_file,contig_name='BF000000.1', kernal_type='diff',plot_kernal=False, read_density_cut=0.2)\n",
    "genes= list(fig_dict.keys()) \n",
    "plus_genes_tss = list(set(genes).intersection(set(tf_sums.plus_strand_genes)))  #get all genes on the +strand that have windows\n",
    "gb_dict = pgb.build_genbank_dict(path_to_annot_file)\n",
    "\n",
    "\n",
    "\n",
    "def get_tss(tss_window):\n",
    "    ser = ndi.convolve(tss_window,[1,0,-1])\n",
    "    df = pd.DataFrame({gene:tss_window, 'diff_kernal':ser}, index = tss_window.index)\n",
    "    filt1 = df.loc[:,'diff_kernal'] > 0\n",
    "    filt2 = df.loc[:,gene] > 0\n",
    "    df = df.loc[filt1,:] \n",
    "    df = df.loc[filt2,:]\n",
    "    d = {}\n",
    "    pre = {}\n",
    "    post = {}\n",
    "    window_size = 20\n",
    "    for position in df.index:\n",
    "        ave_reads = tss_window.sum()/tss_window.shape[0]\n",
    "        pre_window_reads = tss_window.loc[position-window_size:position].sum()\n",
    "        post_window_reads = tss_window.loc[position:position+window_size].sum()\n",
    "        if post_window_reads/window_size < ave_reads/2:\n",
    "            post_window_reads=0\n",
    "        #print(f'position: {position} post_window_reads: {post_window_reads}')\n",
    "        if pre_window_reads==0:\n",
    "            pre_window_reads=pre_window_reads+0.000000001\n",
    "        #print(f'position: {position} pre_window_reads: {pre_window_reads}\\n')\n",
    "        d[position]=(post_window_reads-pre_window_reads)/pre_window_reads\n",
    "        pre[position] = pre_window_reads\n",
    "        post[position] = post_window_reads\n",
    "    df_hypoth = pd.DataFrame().from_dict(d, orient='index')\n",
    "    df_hypoth.columns = ['enrichment']\n",
    "    df_hypoth['post'] = list(post.values())\n",
    "    df_hypoth['pre'] = list(pre.values())\n",
    "    return df_hypoth.sort_values('enrichment', ascending=False)\n",
    "\n",
    "# df_dict = {}\n",
    "# for gene in plus_genes_tss:\n",
    "#     df_dict[gene] = get_tss(tss_windows[gene])\n",
    "\n",
    "\n",
    "###pick a gene\n",
    "# gene = plus_genes_tss[8]\n",
    "for i in range(50):\n",
    "    gene = plus_genes_tss[i]\n",
    "    print(gene)\n",
    "    print(gb_dict['BF000000.1'][gene].location.strand)\n",
    "    print(gb_dict['BF000000.1'][gene].qualifiers['product'])\n",
    "    fig = fig_dict[gene]\n",
    "    df = get_tss(tss_windows[gene])\n",
    "    for i,pos in enumerate(df.index):\n",
    "        if i<1:\n",
    "            fig.add_vline(x=pos,line_width=1, line_dash='dash')\n",
    "    fig.write_html(f'./figs/{gene}_putative_tss.html')\n",
    "\n",
    "a = fig_dict[gene]\n",
    "#pf.get_seq_region(path_to_fa_genomes,'BF000000.1',18757,18857)\n",
    "\n",
    "\n",
    "name='Histogram of read density in tss window'\n",
    "ser = pd.Series(dens_dict.values())\n",
    "#\n",
    "trace = pu.plot_bar_with_outliers(ser, name=name, end = 20)\n",
    "pyo.plot(go.Figure(data=trace))\n",
    "\n",
    "### Sandbox for developing kernal to find steps\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "d = '''594.          568.55555556  577.22222222  624.55555556  546.66666667\n",
    "552.88888889  575.55555556  592.33333333  528.88888889  576.11111111\n",
    "625.          574.22222222  556.33333333  567.66666667  576.66666667\n",
    "591.66666667  566.33333333  567.33333333  547.44444444  631.11111111\n",
    "555.66666667  548.66666667  579.44444444  546.88888889  597.55555556\n",
    "519.88888889  582.33333333  618.88888889  574.55555556  547.44444444\n",
    "593.11111111  565.66666667  544.66666667  562.66666667  554.11111111\n",
    "543.88888889  602.33333333  609.77777778  550.55555556  561.88888889\n",
    "719.33333333  784.44444444  711.22222222  843.66666667  691.33333333\n",
    "690.11111111  684.33333333  749.11111111  759.11111111  653.33333333\n",
    "817.11111111  705.22222222  689.44444444  712.33333333  659.\n",
    "683.88888889  713.          740.44444444  692.22222222  677.33333333\n",
    "681.44444444  640.          717.55555556  717.88888889  769.22222222\n",
    "690.88888889  786.          774.66666667  799.44444444  743.44444444\n",
    "789.88888889  673.66666667  685.66666667  709.88888889  645.55555556\n",
    "846.11111111  792.77777778  702.22222222  749.44444444  678.55555556\n",
    "707.55555556  665.77777778  643.55555556  671.44444444  795.66666667\n",
    "627.22222222  684.55555556  708.44444444  829.66666667  719.        '''\n",
    "\n",
    "dary = np.array([*map(float, d.split())])\n",
    "\n",
    "dary -= np.average(dary)\n",
    "\n",
    "step = np.hstack((np.ones(len(dary)), -1*np.ones(len(dary))))\n",
    "\n",
    "dary_step = np.convolve(dary, step, mode='valid')\n",
    "\n",
    "# get the peak of the convolution, its index\n",
    "\n",
    "step_indx = np.argmax(dary_step)  # yes, cleaner than np.where(dary_step == dary_step.max())[0][0]\n",
    "\n",
    "# plots\n",
    "\n",
    "plt.plot(dary)\n",
    "\n",
    "plt.plot(dary_step/10)\n",
    "\n",
    "plt.plot((step_indx, step_indx), (dary_step[step_indx]/10, 0), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92165cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597784d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
