{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are there sequences near TSS that are associated with up or down regulation by ...  \n",
    "    Call transcripts from merged RNAseq datasets, find TSS region,\n",
    "    Merge RNAseq data to obtain more sequencing depth \n",
    "    Merge .bam files from BAO and BAN experimental set to one bam file\n",
    "    split merged bam file into + strand and - strand files (+ flag 83,163) (-flag 99,147)\n",
    "    index each file\n",
    "    Run stringtie on this indexed + and - bam file to estimate transcripts\n",
    "\n",
    "\n",
    "    Filtering out stringtie transcripts that are more reliable and editing them\n",
    "    filter\n",
    "    Select stringtie transcripts that start between two genes on one of the\n",
    "    DNA strands\n",
    "    Filter out transcripts that\n",
    "    Have low read Density\n",
    "    have no sudden increase in reads over a window of nts\n",
    "    Edit \n",
    "    If stringtie transcript ends in middle of gene, extend transcript to end of that gene\n",
    "    Create GFF from Filtered/edited stringtie transcripts and visualize with genome browser\n",
    "\n",
    "    match known transcripts  with their known TSSs to determine if our predictions \n",
    "    are predicting those correctly\n",
    "\n",
    "    generate file that has:\n",
    "    all predicted TSS sequences from -100 to +50 (wrt TSS)\n",
    "    genes that are included in TU for each TSS\n",
    "    information about whether those genes are upregulated, downregulated, not regulated \n",
    "    TSS1\t….NNNNNN….\trpoD\tnot regulated\n",
    "    TSS1\t…NNNNNN….\tlecA\tnot regulated\n",
    "    TSS2\t…NNNNNN…\t\tdnaA\tupregulated\n",
    "    \n",
    "    determine if there are motifs present in upregulated, downregulated or not regulated \n",
    "    seq using MEME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotly import graph_objects as go\n",
    "import numpy as np\n",
    "import os\n",
    "from jw_utils import genome_utils as gu\n",
    "from jw_utils import parse_gff as pgf\n",
    "from jw_utils import parse_fasta as pf\n",
    "from jw_utils import file_utils as fu\n",
    "import bisect\n",
    "import pysam\n",
    "from transcript_calling import tc_functions as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gff = '../references/FERM_BP3421.gff'\n",
    "path_to_strGTF_neg = './merge_all_negStrand.gtf'\n",
    "path_to_annot_file = '../data/references/Reference_FERM_BP3421.gbk'\n",
    "path_to_fa_genomes = '../data/references/concat_references.fa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split merged bam file into plus and minus strand templates \n",
    "    stringtie seems to perform better for me when I give it only one strand\n",
    "    - rf sequencing  \n",
    "    - plus strand flags: 83, 163\n",
    "    - minus strand flags: 99, 147\n",
    "    samtools view -f 83 merge_all.bam -o flag83.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: samtools: command not found\n",
      "/bin/bash: samtools: command not found\n",
      "/bin/bash: samtools: command not found\n",
      "rm: ./merged_bam_files/flag83.bam: No such file or directory\n",
      "rm: ./merged_bam_files/flag163.bam: No such file or directory\n",
      "/bin/bash: samtools: command not found\n",
      "/bin/bash: samtools: command not found\n",
      "/bin/bash: samtools: command not found\n",
      "/bin/bash: samtools: command not found\n",
      "rm: ./merged_bam_files/flag99.bam: No such file or directory\n",
      "rm: ./merged_bam_files/flag147.bam: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#positive strand genes\n",
    "!samtools view -f 83 ./merged_bam_files/merge_all.bam -o ./merged_bam_files/flag83.bam\n",
    "#!samtools view -f 163 merge_all.bam -o flag163.bam\n",
    "!samtools merge ./merged_bam_files/flag83.bam ./merged_bam_files/flag163.bam -o ./merged_bam_files/merge_all_posStrand.bam\n",
    "!samtools index ./merged_bam_files/merge_all_posStrand.bam\n",
    "!rm ./merged_bam_files/flag83.bam\n",
    "!rm ./merged_bam_files/flag163.bam\n",
    "\n",
    "#neg strand genes\n",
    "!samtools view -f 99 ./merged_bam_files/merge_all.bam -o ./merged_bam_files/flag99.bam\n",
    "!samtools view -f 147 ./merged_bam_files/merge_all.bam -o ./merged_bam_files/flag147.bam\n",
    "!samtools merge ./merged_bam_files/flag99.bam ./merged_bam_files/flag147.bam -o ./merged_bam_files/merge_all_negStrand.bam\n",
    "!samtools index ./merged_bam_files/merge_all_negStrand.bam\n",
    "!rm ./merged_bam_files/flag99.bam\n",
    "!rm ./merged_bam_files/flag147.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call initial transcripts using stringtie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!stringtie -g 0 -j 10 ./merged_bam_files/merge_all_posStrand.bam --rf -o merge_all_posStrand.gtf\n",
    "!stringtie -g 0 -j 10 ./merged_bam_files/merge_all_negStrand.bam --rf -o merge_all_negStrand.gtf\n",
    "!stringtie -g 0 -j 10 ./merged_bam_files/merge_all.bam --rf -o merge_all.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge pos and neg strand annotation files produced by stringtie back into one gff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_nested_obj_dict = tf.merge_pos_neg_sttie_objs('merge_all_posStrand.gtf','merge_all_negStrand.gtf',path_to_gff)\n",
    "tf.write_gff_from_seqobj(merged_nested_obj_dict,'merged_all.gff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make wig files with pilups for each strand for each chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::hts_open_format] Failed to open file \"./merged_bam_files/merge_all_posStrand.bam\" : No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] could not open alignment file `./merged_bam_files/merge_all_posStrand.bam`: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hb/rvrzm3nx3sxcpzvvy7xxwtsw0000gn/T/ipykernel_92983/3614808096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontig_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_contig_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_gff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_wig_pilups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./merged_bam_files/merge_all_posStrand.bam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontig_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_wig_pilups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./merged_bam_files/merge_all_negStrand.bam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontig_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trestle_projects/Eustaquio_lab/Eustaquio_epigenetics/project_1/transcript_calling/tc_functions.py\u001b[0m in \u001b[0;36mmake_wig_pilups\u001b[0;34m(bam_filepath, contig_names)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_wig_pilups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbam_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontig_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0msam_align_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbam_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbam_filepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.bam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcontig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontig_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpysam/libcalignmentfile.pyx\u001b[0m in \u001b[0;36mpysam.libcalignmentfile.AlignmentFile.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpysam/libcalignmentfile.pyx\u001b[0m in \u001b[0;36mpysam.libcalignmentfile.AlignmentFile._open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] could not open alignment file `./merged_bam_files/merge_all_posStrand.bam`: No such file or directory"
     ]
    }
   ],
   "source": [
    "contig_names = pgf.get_contig_names(path_to_gff)\n",
    "tf.make_wig_pilups('./merged_bam_files/merge_all_posStrand.bam', contig_names)\n",
    "tf.make_wig_pilups('./merged_bam_files/merge_all_negStrand.bam', contig_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out stringtie transcripts that are more reliable, and editing them    \n",
    "\n",
    "    filter for  \n",
    "    -Select stringtie transcripts that start between two genes on one of the    \n",
    "     DNA strands  \n",
    "    -Filter out transcripts that  \n",
    "        -Have low read Density  \n",
    "        -have no sudden increase in reads over a window of nts  \n",
    "    Edit   \n",
    "        -If stringtie transcript ends in middle of gene, extend transcript to  \n",
    "         end of that gene  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit  and filter transcripts  \n",
    "tf.filter_transcripts() \n",
    "1) extends each transcript to the stop codon of the nearest gene on the same strand\n",
    "2) filters out transcripts that start in the middle of a gene (on the same strand)\n",
    "3) filters out genes that have below the input threshold reads/nt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_transcript_objs = tf.filter_transcripts('./merged_all.gff',path_to_gff,20,annot_type='gff' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.write_gff_from_seqobj(filtered_transcript_objs, 'merged_all_filtered_20.gff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate file that has:  \n",
    "- all predicted TSS sequences from -100 to +50 (wrt TSS)\n",
    "- genes that are included in TU for each TSS\n",
    "- information about whether those genes are upregulated, downregulated, not regulated \n",
    "        TSS1    ….NNNNNN….    rpoD    not regulated\n",
    "        TSS1    …NNNNNN….    lecA    not regulated\n",
    "        TSS2    …NNNNNN…        dnaA    upregulated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get sequence around a given coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"./notebook_images/get_minusStrand_seq_region2.jpg\" alt=\"get minus strand seq. region\" width=\"400\">\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not return all of upstream sequence requested because reached beginning of contig.\n"
     ]
    }
   ],
   "source": [
    "def make_seqs_around_start_df(upstream, downstream, fasta_genome, feature_obj_dict):\n",
    "    \"\"\"Return df from a nested seq object dictionary with local sequence around start of feature. \n",
    "    \n",
    "    parameters:\n",
    "    upstream (int): # nt to return upstream of feature_beginning\n",
    "    downstream (int): # nt to return downstream of feature_beginning\n",
    "    fasta_genome (str): path_to_fasta_genome\n",
    "    feature_obj_dict (dict): {contig:feature_ID:feature_annot_object}\n",
    "    \"\"\"\n",
    "    info_for_file = {}\n",
    "#     upstream = 100\n",
    "#     downstream = 50\n",
    "    fasta_genome_dict = pf.get_seq_dict(fasta_genome)\n",
    "    seqs = {}\n",
    "    contigs = {}\n",
    "    for contig in filtered_transcript_objs:\n",
    "        for seq_obj_id in filtered_transcript_objs[contig]:\n",
    "            seq_obj = filtered_transcript_objs[contig][seq_obj_id]\n",
    "            strand = seq_obj.strand\n",
    "            if strand == '+':\n",
    "                tss = seq_obj.start\n",
    "            elif strand == '-':\n",
    "                tss = seq_obj.end\n",
    "            contigs[seq_obj_id] = contig\n",
    "            seqs[seq_obj_id] = tf.get_seq_around_coordinate(fasta_genome_dict,\n",
    "                                            contig,strand, tss, upstream, downstream)\n",
    "            \n",
    "    df1 = pd.DataFrame(seqs.values(), seqs.keys())\n",
    "    df2 = pd.DataFrame(contigs.values(), contigs.keys()) \n",
    "    df_seqs= pd.merge(df1,df2,how='inner', left_index=True, right_index=True)\n",
    "    df_seqs.columns =[\"up_down_seq 3'-5'\", 'chromosome']\n",
    "    df_seqs.index.name = 'transcript_ID'\n",
    "    return df_seqs\n",
    "            \n",
    "fasta_concat_genomepath = '../references/concat_references.fa'            \n",
    "df_seqs = make_seqs_around_start_df(100, 50, fasta_concat_genomepath, filtered_transcript_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get genes within the transcript  \n",
    "1) if the start codon of a gene (on the same strand as the transcript) is within the \n",
    "    start:end coordinates of the transcript, then count it as in the gene\n",
    "    - need the gene annotation  and the transcript annotations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genes_in_transcripts_df(path_trans_annots, path_to_gff):\n",
    "    \"\"\"Return df with row with genes, if any, (1 per row) in each transcript\"\"\"\n",
    "    \n",
    "    genes_in_transcript=tf.find_genes_in_transcript(path_trans_annots, path_to_gff)\n",
    "    transcpt_list = []\n",
    "    gene_list = []\n",
    "    num_genes = []\n",
    "    df_git =pd.DataFrame(genes_in_transcript.values(), genes_in_transcript.keys())\n",
    "    for tnscpt, genes in genes_in_transcript.items():\n",
    "        if len(genes)>0:\n",
    "            for gene in genes:\n",
    "                transcpt_list.append(tnscpt)\n",
    "                gene_list.append(gene)\n",
    "                num_genes.append(len(genes))\n",
    "        else:\n",
    "            transcpt_list.append(tnscpt)\n",
    "            gene_list.append(None)\n",
    "            num_genes.append(0)\n",
    "\n",
    "    df_tran_genes = pd.DataFrame()\n",
    "    df_tran_genes['transcript_ID'] = transcpt_list\n",
    "    df_tran_genes['locus_tag'] = gene_list\n",
    "    df_tran_genes['#_genes/trnscrpt'] = num_genes\n",
    "    return df_tran_genes\n",
    "\n",
    "path_trans_annots = './merged_all_filtered_20.gff'\n",
    "df_tran_genes = get_genes_in_transcripts_df(path_trans_annots, path_to_gff)\n",
    "df_seqs_with_genes = pd.merge(df_tran_genes,df_seqs, how='outer', on='transcript_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_ID</th>\n",
       "      <th>locus_tag</th>\n",
       "      <th>#_genes/trnscrpt</th>\n",
       "      <th>up_down_seq 3'-5'</th>\n",
       "      <th>chromosome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STRG.3314</td>\n",
       "      <td>gene-tmp_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>aatccgcgcgcgccatccacaagcccgcccacgaccgtcgacgcct...</td>\n",
       "      <td>BF000000.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STRG.954</td>\n",
       "      <td>gene-tmp_000008</td>\n",
       "      <td>1</td>\n",
       "      <td>ttcgtagtgtagtcgccaaaccgaaaatgccacggtcgggagtgac...</td>\n",
       "      <td>BF000000.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STRG.3315</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>cccgccccggccgccggcgcggtgcacgatccgtcggccccaataa...</td>\n",
       "      <td>BF000000.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STRG.955</td>\n",
       "      <td>gene-tmp_000009</td>\n",
       "      <td>2</td>\n",
       "      <td>gaacctgctcatcggatccgacccttgcaactgttacactttccgc...</td>\n",
       "      <td>BF000000.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STRG.955</td>\n",
       "      <td>gene-tmp_000010</td>\n",
       "      <td>2</td>\n",
       "      <td>gaacctgctcatcggatccgacccttgcaactgttacactttccgc...</td>\n",
       "      <td>BF000000.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>STRG.141</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>cgcaggctcagcggaaaacagtagtacaaccaaacggcgtggcaga...</td>\n",
       "      <td>BF000000.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>STRG.142</td>\n",
       "      <td>gene-tmp_006514</td>\n",
       "      <td>1</td>\n",
       "      <td>cccgcaattgacttgacggtaaattatcagagccagtaaatcgagc...</td>\n",
       "      <td>BF000000.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>STRG.146</td>\n",
       "      <td>gene-tmp_006521</td>\n",
       "      <td>2</td>\n",
       "      <td>agtcgaattgtttcatttaatttgaatatgcatatttgatacagat...</td>\n",
       "      <td>BF000000.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>STRG.146</td>\n",
       "      <td>gene-tmp_006522</td>\n",
       "      <td>2</td>\n",
       "      <td>agtcgaattgtttcatttaatttgaatatgcatatttgatacagat...</td>\n",
       "      <td>BF000000.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>STRG.176</td>\n",
       "      <td>gene-tmp_006531</td>\n",
       "      <td>1</td>\n",
       "      <td>gccgctcgctcattccggaaagcgccgcgtgcattccttcccgccg...</td>\n",
       "      <td>BF000000.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1782 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     transcript_ID        locus_tag  #_genes/trnscrpt  \\\n",
       "0        STRG.3314  gene-tmp_000007                 1   \n",
       "1         STRG.954  gene-tmp_000008                 1   \n",
       "2        STRG.3315             None                 0   \n",
       "3         STRG.955  gene-tmp_000009                 2   \n",
       "4         STRG.955  gene-tmp_000010                 2   \n",
       "...            ...              ...               ...   \n",
       "1777      STRG.141             None                 0   \n",
       "1778      STRG.142  gene-tmp_006514                 1   \n",
       "1779      STRG.146  gene-tmp_006521                 2   \n",
       "1780      STRG.146  gene-tmp_006522                 2   \n",
       "1781      STRG.176  gene-tmp_006531                 1   \n",
       "\n",
       "                                      up_down_seq 3'-5'  chromosome  \n",
       "0     aatccgcgcgcgccatccacaagcccgcccacgaccgtcgacgcct...  BF000000.1  \n",
       "1     ttcgtagtgtagtcgccaaaccgaaaatgccacggtcgggagtgac...  BF000000.1  \n",
       "2     cccgccccggccgccggcgcggtgcacgatccgtcggccccaataa...  BF000000.1  \n",
       "3     gaacctgctcatcggatccgacccttgcaactgttacactttccgc...  BF000000.1  \n",
       "4     gaacctgctcatcggatccgacccttgcaactgttacactttccgc...  BF000000.1  \n",
       "...                                                 ...         ...  \n",
       "1777  cgcaggctcagcggaaaacagtagtacaaccaaacggcgtggcaga...  BF000000.3  \n",
       "1778  cccgcaattgacttgacggtaaattatcagagccagtaaatcgagc...  BF000000.3  \n",
       "1779  agtcgaattgtttcatttaatttgaatatgcatatttgatacagat...  BF000000.3  \n",
       "1780  agtcgaattgtttcatttaatttgaatatgcatatttgatacagat...  BF000000.3  \n",
       "1781  gccgctcgctcattccggaaagcgccgcgtgcattccttcccgccg...  BF000000.3  \n",
       "\n",
       "[1782 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seqs_with_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add gene expression data (up and down-regulated genes) to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gene_expression_data_add_up_down(data_path, up_thresh, down_thresh, pval_thresh):\n",
    "    df_expression = pd.read_csv(data_path, sep='\\t')\n",
    "    pval_filt = df_expression['PValue']<pval_thresh\n",
    "    df_expression = df_expression.loc[pval_filt,:]\n",
    "    filt_up = df_expression['logFC']>up_thresh\n",
    "    filt_down = df_expression['logFC']<down_thresh\n",
    "    up_down = []\n",
    "    for up,down in zip(filt_up,filt_down):\n",
    "        if up:\n",
    "            up_down.append('up')\n",
    "        elif down:\n",
    "            up_down.append('down')\n",
    "        else:\n",
    "            up_down.append('not significant')\n",
    "    df_expression['regulation'] = up_down\n",
    "    return df_expression\n",
    "\n",
    "data_path = './differentially_regulated_genes_BANvBAO.tsv'\n",
    "df_expression = filter_gene_expression_data_add_up_down(data_path,1.0, -1.0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_seqs_with_genes.columns = ['transcript_ID', 'locus_tag', \n",
    "                              '#_genes/trnscrpt', \"up_down_seq 3'-5\",'chromosome']\n",
    "df_seqs_with_genes['locus_tag'] = [gene.replace('gene-', '') if gene else None for gene in df_seqs_with_genes['locus_tag']]\n",
    "df_expression.columns = ['locus_tag', 'gene', 'description', 'featureType', 'logFC', 'pValue',\n",
    "       'FDR', 'BAO-1', 'BAO-2', 'BAO-3', 'BAN-1', 'BAN-2', 'BAN-3','regulation']\n",
    "df_full= pd.merge(df_seqs_with_genes,df_expression, how='inner', on='locus_tag').set_index('transcript_ID')\n",
    "#df3 = df3[['chromosome', 'genes', '#_genes_in_trnscrpt',\n",
    "       #'Gene', 'Description', 'regulation', 'PValue', 'logFC', \"up_down_seq 3'-5'\"]]\n",
    "df_full = df_full[['#_genes/trnscrpt','locus_tag', 'chromosome',\n",
    "       'gene', 'description','regulation', 'logFC', 'pValue', 'FDR', 'BAO-1',\n",
    "       'BAO-2', 'BAO-3', 'BAN-1', 'BAN-2', 'BAN-3', \"up_down_seq 3'-5\" ]]\n",
    "df_full.to_csv('transcipts_genes_regulation_BAOvBAN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Locustag', 'Gene', 'Description', 'FeatureType', 'logFC', 'PValue',\n",
       "       'FDR', 'BAO-1', 'BAO-2', 'BAO-3', 'BAN-1', 'BAN-2', 'BAN-3',\n",
       "       'regulation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volcano plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transcript_ID', 'up_down_seq 3'-5'', 'chromosome', 'genes',\n",
       "       '#_genes_in_trnscrpt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df3 = df3[[]]\n",
    "df_merge.columns = ['Transcript_ID', \"Up_down_seq 3'-5'\", 'Chromosome', 'Locustag',\n",
    "       '#_genes/trnscrpt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate file that has:  \n",
    "- all predicted TSS sequences from -100 to +50 (wrt TSS)\n",
    "- genes that are included in TU for each TSS\n",
    "- information about whether those genes are upregulated, downregulated, not regulated \n",
    "        TSS1    ….NNNNNN….    rpoD    not regulated\n",
    "        TSS1    …NNNNNN….    lecA    not regulated\n",
    "        TSS2    …NNNNNN…        dnaA    upregulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        2.033241\n",
       "5        2.664175\n",
       "9       12.077312\n",
       "10      10.234666\n",
       "11       0.200274\n",
       "          ...    \n",
       "1522    18.503156\n",
       "1523    24.151807\n",
       "1524    21.638660\n",
       "1525    14.008044\n",
       "1526    22.592076\n",
       "Length: 617, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph read density on filtered transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coverage_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hb/rvrzm3nx3sxcpzvvy7xxwtsw0000gn/T/ipykernel_96624/2280616836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilt_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcoverage_fil_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoverage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoverage_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coverage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mfilt_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coverage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbins\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrnge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'coverage_df' is not defined"
     ]
    }
   ],
   "source": [
    "filt_val = 20\n",
    "coverage_fil_df = coverage_df.loc[coverage_df['coverage']>filt_val,:].sort_values('coverage')\n",
    "\n",
    "bins  = 50\n",
    "rnge = (0,75)\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "hist = np.histogram(coverage_fil_df['coverage'],bins=bins, range=rnge)\n",
    "trace1 = go.Bar(x=hist[1], y=hist[0], name='coverage')\n",
    "layout = go.Layout({'title':'histogram of ave. reads/nt'})\n",
    "fig = go.Figure(data=[trace1], layout=layout )\n",
    "fig.update_xaxes({'title':\n",
    "                      {'text':'ave. reads/nt',\n",
    "                      'font':{'size':20}}\n",
    "                 })\n",
    "fig.update_yaxes({'title':\n",
    "                      {'text':'number of transripts',\n",
    "                      'font':{'size':20}}\n",
    "                 })\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "6691013dd57765de18105885afeee5e2162f23612599fe49b9f063fc824dadcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
